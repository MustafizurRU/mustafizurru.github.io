<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>Md Mustafizur Rahman - NAIST</title>
    <link rel="icon" type="image/png" href="../image/m.png"/>
    <meta name="description" content="Md Mustafizur Rahmanの個人ページ。"/>
    <meta http-equiv="author" content="Md Mustafizur Rahman"/>
    <link rel="stylesheet" type="text/css" href="../css/main.css?v=1.0.0">
</head>

<body>

<div id="navigator">
    <ul>
        <li><a href="#navigator">プロフィール</a></li>
        <li><a href="#work_experience">経験</a></li>
        <li><a href="#research">研究</a></li>
        <li><a href="#project">プロジェクト</a></li>
        <li><a href="#awards">受賞歴</a></li>
        <li><a href="#blog">ブログ</a></li>
    </ul>
</div>

<div id="wrapper">
    <!-- profile block -->
    <div id="profile">
        <div id="profile_content">
            <div id="profile_content_name">
                <div id="profile_content_name_text">Md Mustafizur Rahman</div>
            </div>

            <div id="profile_content_description">
                修士課程学生 <br/>
                <a href="https://imdl.naist.jp/">インタラクティブメディアデザイン研究室</a> <br/>
                <a href="http://isw3.naist.jp/home-en.html">情報科学研究科</a> <br/>
                <a href="http://isw3.naist.jp/home-en.html">先端科学技術研究科</a> <br/>
                <a href="https://www.naist.jp/en/">奈良先端科学技術大学院大学</a> <br/>
                <br/>
                メール: rahman.md_mustafizur.rp6@naist.ac.jp <br/>
                <a href="../files/Mustafizur_Resume.pdf" target="_blank" class="special_link">履歴書</a>
                <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" target="_blank" class="special_link">Google Scholar</a>
            </div>
        </div>

        <div id="profile_image">
            <img src="../image/mustafizur.jpg" class="align-center" alt="Md Mustafizur Rahman" width="120" height="160">
        </div>
    </div>

    <div class="item_block" id="aboutme">
        <div class="item_headline">
            <h2>私について</h2>
        </div>
        <div id="aboutme_content">
            <p>私は、<a href="https://www.naist.jp/en/" target="_blank" class="light_blue_link">奈良先端科学技術大学院大学</a>の修士課程の学生で、情報科学のバックグラウンドを持っています。</p>
            <p>私の研究は、AI、AR、VR技術を活用して、理学療法、医療トレーニング、リハビリテーションを向上させることに焦点を当てています。</p>
            <p>ソフトウェアエンジニアリング、コンピュータビジョン、インタラクティブメディアデザインを組み合わせた革新的なソリューションの開発に情熱を注いでいます。</p>
            <p>ピクセルが大好きで、シンプルな直感と創造的な思考の力を信じています。</p>
        </div>
    </div>


    <div class="item_block" id="work_experience">
        <div class="item_headline">
            <h2>職務経験</h2>
        </div>

        <table>
            <tr>
                <td class="work_description">
                    <a href="https://imdl.naist.jp/" class="light_blue_link" target="_blank">インタラクティブメディアデザイン研究室</a> | 修士課程学生 | 研究者 <br>
                    2023年10月 ～ 現在 | 日本、奈良県生駒市高山町8916-5、630-0192 <br>
                    &bull; 「患者特有の歩行動作のシミュレーションによる理学療法における体験の拡張」という研究プロジェクトに従事し、HumanML3Dデータセットを利用しています。<br>
                    &bull; 著名な指導教員<a href="https://scholar.google.com/citations?user=zlyaC60AAAAJ&hl=en" class="light_blue_link" target="_blank">加藤弘和教授</a>および他の助教授<a href="https://scholar.google.com/citations?user=5vnFG2sAAAAJ&hl=ja" class="light_blue_link" target="_blank">沢部大志</a>と<a href="https://scholar.google.com/citations?user=5qcS7IoAAAAJ&hl=en" class="light_blue_link" target="_blank">イスドロ・ブタスラク</a>によって指導を受けています。<br>
                    &bull; 個別化された歩行動作のシミュレーションを通じて、理学療法を向上させる革新的なソリューションの開発に焦点を当てています。<br>
                    &bull; 患者のリハビリテーションの成果を改善することを目指した最先端の研究に貢献し、没入型3Dモーションシミュレーションを提供しています。<br>
                    &bull; 拡張現実（AR）、仮想現実（VR）、および複合現実（MR）の専門知識を活用して、動的で患者特有の動作表現を作成しています。<br>
                    &bull; ジェネレーティブAI技術およびBERTを含む大規模言語モデル（LLM）を適用し、改善された治療応用のために障害のある人間の動作データを分析および生成しています。<br>
                </td>
                <td class="work_image" id="naist_img">
                    <img src="../image/imd_lab.png" alt="インタラクティブメディアデザイン研究室" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://www.kyoto-u.ac.jp/en" class="light_blue_link" target="_blank">京都大学</a> | 研究協力者 <br>
                    2024年3月 ～ 現在 | 日本、京都市左京区川原町54、606-8507 <br>
                    &bull; 臨床研究センターの<a href="https://scholar.google.com/citations?user=Oz9_9Z8AAAAJ&hl=en" class="light_blue_link" target="_blank">山本剛史</a>、<a href="https://scholar.google.co.jp/citations?user=jhNjdXcAAAAJ&hl=ja" class="light_blue_link" target="_blank">劉昌</a>、および<a href="https://researchmap.jp/hiro-ueshima" class="light_blue_link" target="_blank">上嶋博明</a>教授と協力しています。<br>
                    &bull; 「患者特有の歩行動作のシミュレーションによる理学療法における体験の拡張」という研究に従事し、高度なシミュレーション技術を通じてリハビリテーションの成果を向上させています。<br>
                    &bull; 理学療法の現場におけるリハビリテーションの最適化に焦点を当てた学際的プロジェクトに参加しています。<br>
                    &bull; ジェネレーティブAIおよびBERTなどのLLMを統合し、治療介入を改善し、患者コミュニケーションを強化しています。<br>
                    &bull; 拡張現実（AR）、仮想現実（VR）、および複合現実（MR）を活用して、理学療法士のための没入型学習体験を促進するインタラクティブツールを開発し、多様な障害のある歩行パターンをシミュレートしています。<br>
                </td>
                <td class="work_image" id="kyoto_university_img">
                    <img src="../image/kyoto_uni.png" alt="京都大学" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://talentpro.global/" target="_blank" class="light_blue_link">タレントプロ</a> | チームリード - ソフトウェア品質保証エンジニア <br>
                    2022年6月 ～ 2023年8月 | バングラデシュ、ダッカ市バナニ、旧DOHS109番地 <br>
                    &bull; タレントプロでの各プロジェクトのテストプロセスを管理し、QA活動をリードしました。 <br>
                    &bull; テスト計画、テストケースを作成し、自動化テストスクリプトを設計しました。<br>
                    &bull; テスト実行結果の分析を行いました。 <br>
                    &bull; Javaベースの自動化フレームワーク内でのAppium、Selenium WebDriver、TestNG、Cucumberに特化しました（TDD、BDD）。 <br>
                    &bull; REST AssuredおよびGraphQLを使用してAPIテスト、パフォーマンステスト、セキュリティテスト、データベーステストを管理しました。
                </td>
                <td class="work_image" id="talentpro_img">
                    <img src="../image/talentpro-global-logo.jpg" alt="タレントプロ" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://realezy.com/" target="_blank" class="light_blue_link">RealEzy（シンガポール）</a> | ソフトウェア品質保証エンジニア <br>
                    2022年6月 ～ 2023年8月 | タレントプロのシンガポールプロジェクト <br>
                    &bull; シンガポールの不動産プラットフォームであるRealEzyのプロジェクトに専任QA役として採用されました。 <br>
                    &bull; テストプロセスの自動化、テスト計画の設計、および手動と自動テストを通じてソフトウェア品質を確保する責任を負いました。 <br>
                    &bull; Appium、Selenium、およびJavaベースの自動化フレームワークを駆使して、RealEzyのプラットフォームのテスト作業を効率化しました。 <br>
                    &bull; REST Assuredを使用してAPI、パフォーマンス、セキュリティテストを実施し、プラットフォームの最適な機能を確保しました。
                </td>
                <td class="work_image" id="realezy_img">
                    <img src="../image/realEzy_Logo.svg" alt="RealEzy" width="140" height="49">
                </td>
            </tr>

            <tr>
                <td class="work_description">
                    <a href="https://fanfare.com.bd/" target="_blank" class="light_blue_link">Fanfare（バングラデシュ）</a> | チームリード - ソフトウェア品質保証エンジニア <br>
                    2023年3月 ～ 2023年5月 | タレントプロのバングラデシュプロジェクト <br>
                    &bull; ソーシャルコマースプラットフォームであるFanfareに割り当てられ、3か月間ソフトウェアリリースの品質を確保しました。 <br>
                    &bull; プラットフォームの品質保証を支援するためにテスト計画、テストケース、および自動化スクリプトを作成しました。 <br>
                    &bull; プロジェクトの進捗状況に基づき、テスト活動を管理しました。 <br>
                    &bull; 開発者と連携して、欠陥の特定と修正を実施しました。<br>
                </td>
                <td class="work_image" id="fanfare_img">
                    <img src="../image/fanfarelogo.png" alt="Fanfare" width="140" height="49">
                </td>
            </tr>

        </table>
    </div>


    <!--Research -->
    <div class="item_block" id="research">
        <div class="item_headline">
            <h2>研究 </h2>
        </div>

        <!-- Specific-Motion -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                    <td class="project_image"><img src="../image/research-img/1TeaserImage.png" class="align-center"
                                                   alt="特定の歩行動作 " width="800" height="236"/></td>
                </tr>
                <tr>
                    <td class="project_title"><a href="#" class="project_title_link">患者特有の歩行動作をシミュレーションすることで
                        リハビリテーションを強化する体験の拡張</a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" class="light_blue_link"
                           target="_blank"><b>Md Mustafizur Rahman</b></a>,
                        <a href="https://scholar.google.com/citations?user=Oz9_9Z8AAAAJ&hl=en" class="light_blue_link"
                           target="_blank">山本剛士</a>,
                        <a href="https://scholar.google.co.jp/citations?user=jhNjdXcAAAAJ&hl=ja" class="light_blue_link"
                           target="_blank">劉暢</a>,
                        <a href="https://researchmap.jp/hiro-ueshima" class="light_blue_link" target="_blank">上島弘明</a>,
                        <a href="https://scholar.google.com/citations?user=5qcS7IoAAAAJ&hl=en" class="light_blue_link"
                           target="_blank">イシドロ・ブタスラク</a>,
                        <a href="https://scholar.google.com/citations?user=5vnFG2sAAAAJ&hl=ja" class="light_blue_link"
                           target="_blank">佐羽太志</a>,
                        <a href="https://scholar.google.com/citations?user=zlyaC60AAAAJ&hl=en" class="light_blue_link"
                           target="_blank">加藤博一</a>
                    </td>
                <tr>
                <tr>
                    <td class="project_description">
                        <p>
                            私たちは、<strong>HumanML3Dデータセット</strong>を用いて<strong>障害のある歩行パターン</strong>の理解を
                            深める<strong>物理療法訓練</strong>のための新しいシステムを提案します。私たちのアプローチは、テキスト記述から
                            動作の長さを予測するための<strong>分類モデル</strong>と、多様な3D動作シーケンスを生成するための
                            <strong>時間的変分オートエンコーダー</strong>を組み合わせています。<strong>残差ベクトル量子化</strong>と
                            <strong>マスキングされたトランスフォーマー</strong>を利用することで、システムは<strong>正確で一貫した動作生成</strong>を
                            確保します。この<strong>インタラクティブなツール</strong>は、セラピストが<strong>患者特有の動作</strong>を
                            <strong>混合現実環境</strong>でシミュレートすることを可能にし、治療訓練を変革し、リハビリテーション戦略を
                            個別化します。
                        </p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p>
                            <strong>開発概要：</strong>この研究では、<strong>Python</strong>と<strong>C#</strong>を使用して
                            アプリケーションを開発し、開発プラットフォームとして<strong>Unity3D</strong>を活用しました。
                            <strong>FastAPI</strong>をバックエンドサービスに組み込み、生成した動作をターゲット3Dモデルのスケルトンに
                            マッピングするために<strong>Blender Python API</strong>を利用しました。開発環境は
                            <strong>PyCharm</strong>で設定し、没入型体験のためにアプリケーションを<strong>Meta Quest 3</strong>に
                            デプロイしました。
                        </p>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <a href="#" class="project_link">保留中</a>
                    </td>
                </tr>
                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">トップに戻る</a></div>
        </div>
        <!-- HealOvr -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                    <td class="project_image"><img src="../image/research-img/OverallArchitecture.jpg" class="align-center"
                                                   alt="特定の歩行動作 " width="800" height="236"/></td>
                </tr>
                <tr>
                    <td class="project_title"><a href="#" class="project_title_link">バーチャルリアリティに基づく医療トレーニングシミュレーターおよびロボット手術システム</a></td>
                </tr>
                <tr>
                    <td class="project_author">
                        <a href="https://scholar.google.com/citations?user=YEVQ5b0AAAAJ&hl=en" class="light_blue_link"
                           target="_blank"><b>Md Mustafizur Rahman</b></a>,
                        <a href="https://www.linkedin.com/in/md-fatin-ishmam-5567b3155/" class="light_blue_link"
                           target="_blank">Md Fatin Ishmam</a>,
                        <a href="https://scholar.google.com/citations?user=CwkzwcQAAAAJ&hl=en" class="light_blue_link"
                           target="_blank">Md. タンビル・ホッサイン</a>,
                        <a href="https://scholar.google.com/citations?hl=en&user=D0cqricAAAAJ" class="light_blue_link"
                           target="_blank">Md. エムダドル・ハク</a>,
                    </td>
                <tr>
                <tr>
                    <td class="project_description">
                        <p>本研究では、医療教育の学習を向上させるためのバーチャルリアリティ（VR）医療トレーニングシミュレーターを紹介します。
                            3Dモデルを使用して、学生は人間の解剖学や生理学をインタラクティブに探求し、外科手術を行い、
                            実際の人間の制約なしに繰り返し練習することができます。さらに、このシステムはロボットプラットフォームに接続されており、
                            熟練した外科医がVRを使用してロボットツールを制御することでリモート手術を行うことができます。
                            これにより、遠隔地にいる患者が専門医療のために都市に移動する必要がなくなり、医療トレーニングとリモート手術のための
                            革新的なソリューションを提供します。</p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p><strong>開発概要：</strong>このプロジェクトでは、アプリケーション開発に<strong>C#</strong>を使用し、
                            <strong>Firebase</strong>を介した通信ブリッジに<strong>C++</strong>を使用しました。
                            <strong>Unity3D</strong>エンジンを使用してUIや部屋のデザインを行い、リアルタイムの<strong>ビデオ伝送</strong>を
                            <strong>TCP/IP</strong>で行い、外科医のモニタリングをVRで可能にしました。
                            <strong>Photon Network</strong>はマルチユーザー協力を促進し、ロボットシステムは
                            <strong>Arduino Mega2560</strong>を使用して制御され、ロボットアクションのために<strong>JSON</strong>で
                            送信されたコマンドを実行しました。</p>
                </tr>
                <tr>
                    <td class="project_appendix">
                        [<a href="https://ieeexplore.ieee.org/abstract/document/10188546" class="project_link">論文</a>]
                </tr>
                </td>
                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">トップに戻る</a></div>
        </div>
    </div>

    <!--Project -->
    <div class="item_block" id="project">
        <div class="item_headline">
            <h2>プロジェクト</h2>
        </div>

        <!-- AR Pose Trainer -->
        <div class="project_item">
            <table>
                <tbody>
                <tr>
                    <td class="project_image">
                        <img src="../image/project-img/ARPoseTrainer.png" class="align-center" alt="特定の歩行動作" width="800" height="236"/>
                    </td>
                </tr>
                <tr>
                    <td class="project_title">
                        <a href="https://drive.google.com/file/d/1GU9YgjXGqyFPv7kpbDkelXkG7q63cEy_/view" target="_blank" class="project_title_link">PoseTrainer: モーターリハビリテーションのための拡張現実サポートシステム</a>
                    </td>
                </tr>
                <tr>
                    <td class="project_author">
                        <b>Md Mustafizur Rahman</b>
                    </td>
                </tr>
                <tr>
                    <td class="project_description">
                        <p>このシステムは、拡張現実（AR）を統合してモーターリハビリテーションをサポートし、リアルタイムの動作分析とフィードバックを提供します。
                            深度センサー（Azure Kinect）が患者の動作データをキャプチャし、PCで処理されて骨格トラッキングの視覚化が生成されます。
                            これらのデータはUDP/IPを介してARデバイス（HoloLensなど）に送信され、セラピストと患者がリアルタイムで仮想アバターと対話できるようになります。
                            このシステムは、ポーズの精度とパフォーマンススコアに関する即時フィードバックを提供し、リハビリテーションを強化し、モーター技能の改善のための没入型で正確なガイダンスとモニタリングを提供します。</p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">
                        <p><strong>開発の概要:</strong> このシステムは、モーターリハビリテーションのために<strong>拡張現実（AR）</strong>を利用し、リアルタイムの動作分析とフィードバックを提供します。
                            <strong>Azure Kinect</strong>が患者の動作をキャプチャし、<strong>C#</strong>で処理され、骨格トラッキングの視覚化が作成され、<strong>UDP/IP</strong>を介して<strong>HoloLens</strong>などのデバイスに送信されます。
                            ポーズの精度とパフォーマンスメトリクスに関する即時フィードバックが提供され、<strong>Laravel REST API</strong>を用いた<strong>PHP</strong>と<strong>MySQL</strong>データベースがスコアの保存と個別のパフォーマンスデータへのアクセスをウェブインターフェースを通じて可能にします。</p>
                    </td>
                </tr>
                <tr>
                    <td class="project_appendix">[
                        <a href="https://drive.google.com/file/d/1GU9YgjXGqyFPv7kpbDkelXkG7q63cEy_/view" target="_blank" class="project_link">動画</a> |
                        <a href="https://github.com/mustafizur-r/arposetrainerapp-live" target="_blank" class="project_link">コード</a>]
                    </td>
                </tr>
                </tbody>
            </table>
            <div class="back_to_top"><a href="#navigator" class="black_link">トップに戻る</a></div>
        </div>
    </div>
    <!--End Project -->


    <!--Awards -->
    <div class="item_block" id="awards">
        <div class="item_headline">
            <h2>受賞歴と業績</h2>
        </div>

        <div class="cv_item_content" id="award_content">
            <div class="award_item">
                <table class="award_table">
                    <thead class="award_table_head">
                    <tr>
                        <th scope="col" class="awards_year_head">年</th>
                        <th scope="col" class="award_number">賞/認識</th>
                        <th scope="col" class="award_title_head">タイトル</th>
                        <th scope="col" class="award_country_head">国</th>
                    </tr>
                    </thead>
                    <tbody>
                    <tr>
                        <td class="award_number">2025年3月～5月</td>
                        <td class="award_number">Erasmus ICM<br>(ノミネーション完了)</td>
                        <td class="award_title">Erasmus International Credit Mobility (ICM) 交換プログラム</td>
                        <td class="award_country">イタリア</td>
                    </tr>
                    <tr>
                        <td class="award_number">2023-2025</td>
                        <td class="award_number">文部科学省（MEXT）</td>
                        <td class="award_title">MEXT奨学金修士課程学生</td>
                        <td class="award_country">日本</td>
                    </tr>
                    <tr>
                        <td class="award_number">2023年</td>
                        <td class="award_number">テクノロジー・ジーニアス賞</td>
                        <td class="award_title">TalentProチームリーダー</td>
                        <td class="award_country">バングラデシュ</td>
                    </tr>
                    <tr>
                        <td class="award_number">2019年</td>
                        <td class="award_number">第1位入賞</td>
                        <td class="award_title">BUET冬季学校ハッカソン</td>
                        <td class="award_country">バングラデシュ</td>
                    </tr>
                    <tr>
                        <td class="award_number">2019年</td>
                        <td class="award_number">第1位入賞</td>
                        <td class="award_title">LICT就職フェアプロジェクト展示</td>
                        <td class="award_country">バングラデシュ</td>
                    </tr>
                    </tbody>
                </table>
                <div class="back_to_top">
                    <a href="#navigator" class="black_link">トップに戻る</a>
                </div>
            </div>
        </div>
    </div>
    <!--End Awards -->

</div>
</body>
</html>
